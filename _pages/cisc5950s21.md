---
layout: post
title: Big Data Programming
permalink: /teaching/5950
description:
---


#### Description (CISC 5950, Spring 2021)

<div style="text-align: justify">
This course covers Apache Hadoop and Spark technologies and their ecosystems in the context of mining big data. It provides students both theoretical background and hands-on computing techniques in big data analytics and its applications. The students will learn how to collect, query, and analyze data. Topics include Hadoop core technologies (HDFS, MapReduce, Yarn), Spark Streaming, MLlib, Clustering, and Spark SQL. Scala programming language will be taught as part of the Spark component.
<br>
<br>
</div>


 ---

- Instructor: Dr. Ying Mao
- Lectures: Wednesday 5:30 p.m. - 7:45 p.m.
- Location: Online
- Email: ymao41 at fordham
- Office: Online
- Office Hours: by appointment

---

#### Lecture Plan

<div style="text-align: justify">

The various course materials, including assignments will be listed in this webpage.
Please check back regularly.

</div>

1. `Course Logistics and Introduction to Big Data Systems`
	- Lecture Materials:
		- Slides are available on Blackboard.
		- Assignment:
			- Create your cloud service account ([Google](https://cloud.google.com/free/), [Azure](https://azure.microsoft.com/en-us/free/), and [AWS](https://aws.amazon.com/free/)).
			- Hand-on: Start a <span style="color:red"> computing virtual machine </span> on the cloud and run "Hello World" Java/Python programs to make sure you have the environment.
				- [Google Quick Start](https://cloud.google.com/compute/docs/quickstart-linux)
				- [Azure Start a VM](https://docs.microsoft.com/en-us/azure/virtual-machines/linux/quick-create-portal)
				- [AWS EC2](https://aws.amazon.com/getting-started/tutorials/launch-a-virtual-machine/)
			- Note: We will mainly focuse on computing resources on the cloud, not networking, storage and other services.
			- PS: Please pay attention to your bill settings and always remember to close the cloud instance when you are done.
		- Reading: Probably most of you already know how to use "git" for version management. For those of you not familiar with "git", please read the [link](https://git-scm.com/docs/gittutorial). Not in a hurry, but we need it in the future labs and projects. <br>

2. `Hadoop Distributed File System and Hands-on Examples`
	- Lecture Materials:
		- Slides are available on Blackboard.
		- Assignment:
			- Follow the instructions and complete the 3-node cluster configuration.
			- Read the code on github HDFS-Test.
			- Read the command HDFS commands, [Link](https://data-flair.training/blogs/top-hadoop-hdfs-commands-tutorial/). <br>

3. `MapReduce Programming Framework`
	- Lecture Materials:
  		- Slides are available on Blackboard.
  		- Assignment:
  			- Set up the HDFS and MapReduce 3-node cluster and check out the webpage, 50070 for HDFS and 8088 for MapReduce
  			- Run the examples of HDFS AND MapReduce on the cloud
  			- <span style="color:red"> Read and understand the code for both HDFS AND MapReduce (the python or java code, not the configuration scripts) </span>
  	- Reading Assignment:
  		- MapReduce toturial: [link](https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html).
  		- Materials of the basic Maven: [Maven-1](https://maven.apache.org/what-is-maven.html), [Maven-2](https://maven.apache.org/guides/getting-started/maven-in-five-minutes.html)<br>

4. `Resource Management on the Cloud and YARN`
	- Lecture Materials:
  		- Slides are available on Blackboard.
  		- Assignment:
  			- Lab 1 has been posted on Blackboard
  			- Online reading:
  				- [Hadoop Capacity Scheduler](https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html)
  				- [Hadoop Fair Scheduler](https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/FairScheduler.html)
  				- [Hadoop Yarn](https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)
  				- Passing parameters to Hadoop Streaming Python: [link](http://www.tnoda.com/blog/2013-11-23)
  				- Passing parameters to shell: [link](https://www.lifewire.com/pass-arguments-to-bash-script-2200571).
  			- Run the experiments in `yarn-test` on your Google Cloud (please open port 9000)
  			- <span style="color:red"> Please `git pull` for the latest code in `mapreduce-test` folder and read the CODE for examples in the `mapreduce-test`</span>
  			- Optional: Conduct Hadoop MapReduce experiments on Intel HiBench: [link](https://github.com/intel-hadoop/HiBench). (In fact, if you read the code, you will see that our `yarn-test` is based on HiBench.)<br>





----
